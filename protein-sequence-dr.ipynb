{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n","metadata":{"execution":{"iopub.status.busy":"2021-11-21T23:19:28.507481Z","iopub.execute_input":"2021-11-21T23:19:28.508049Z","iopub.status.idle":"2021-11-21T23:19:28.51311Z","shell.execute_reply.started":"2021-11-21T23:19:28.50801Z","shell.execute_reply":"2021-11-21T23:19:28.512317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seq = pd.read_csv('../input/protein-data-set/pdb_data_seq.csv')\n#This loads a set of pdb data from kaggle\n\nseq.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-11-21T23:19:28.644779Z","iopub.execute_input":"2021-11-21T23:19:28.645375Z","iopub.status.idle":"2021-11-21T23:19:30.130264Z","shell.execute_reply.started":"2021-11-21T23:19:28.645334Z","shell.execute_reply":"2021-11-21T23:19:30.129003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seq.describe()","metadata":{"execution":{"iopub.status.busy":"2021-11-21T23:19:30.132425Z","iopub.execute_input":"2021-11-21T23:19:30.132929Z","iopub.status.idle":"2021-11-21T23:19:30.167878Z","shell.execute_reply.started":"2021-11-21T23:19:30.132877Z","shell.execute_reply":"2021-11-21T23:19:30.166663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seq = seq.dropna(axis=0)\n#This gets rid of entries which are missing data\nseq.describe()\n","metadata":{"execution":{"iopub.status.busy":"2021-11-21T23:19:30.170379Z","iopub.execute_input":"2021-11-21T23:19:30.17083Z","iopub.status.idle":"2021-11-21T23:19:30.415211Z","shell.execute_reply.started":"2021-11-21T23:19:30.170782Z","shell.execute_reply":"2021-11-21T23:19:30.413898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"structure = pd.read_csv('../input/protein-data-set/pdb_data_no_dups.csv')\nstructure.head()\n#This loads a second set of pdb data from kaggle","metadata":{"execution":{"iopub.status.busy":"2021-11-21T23:19:30.416943Z","iopub.execute_input":"2021-11-21T23:19:30.417266Z","iopub.status.idle":"2021-11-21T23:19:30.97935Z","shell.execute_reply.started":"2021-11-21T23:19:30.417236Z","shell.execute_reply":"2021-11-21T23:19:30.978296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"structure.describe()","metadata":{"execution":{"iopub.status.busy":"2021-11-21T23:19:30.981081Z","iopub.execute_input":"2021-11-21T23:19:30.981727Z","iopub.status.idle":"2021-11-21T23:19:31.0819Z","shell.execute_reply.started":"2021-11-21T23:19:30.981678Z","shell.execute_reply":"2021-11-21T23:19:31.080941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"structure=structure.dropna(axis=0)\n#This gets rid of entries in that second data set which are missing data\nstructure.describe()\n","metadata":{"execution":{"iopub.status.busy":"2021-11-21T23:19:31.083182Z","iopub.execute_input":"2021-11-21T23:19:31.083748Z","iopub.status.idle":"2021-11-21T23:19:31.234916Z","shell.execute_reply.started":"2021-11-21T23:19:31.083704Z","shell.execute_reply":"2021-11-21T23:19:31.233646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = seq.set_index('structureId').merge(structure.set_index('structureId'),on='structureId',how='left')\ndf = df.reset_index()\ndf.head()\ndf.describe()","metadata":{"execution":{"iopub.status.busy":"2021-11-21T23:19:31.236413Z","iopub.execute_input":"2021-11-21T23:19:31.236832Z","iopub.status.idle":"2021-11-21T23:19:32.253786Z","shell.execute_reply.started":"2021-11-21T23:19:31.236791Z","shell.execute_reply":"2021-11-21T23:19:32.252598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y=structure.resolution\nprediction_features = ['residueCount', 'structureMolecularWeight', 'crystallizationTempK', 'phValue','publicationYear', 'densityMatthews', 'densityPercentSol', ]\nX=structure[prediction_features]\nX.describe\n#This selects the features of the database to look at...we're predicting resolution based on a bunch of different factors","metadata":{"execution":{"iopub.status.busy":"2021-11-21T23:19:32.256211Z","iopub.execute_input":"2021-11-21T23:19:32.256662Z","iopub.status.idle":"2021-11-21T23:19:32.274926Z","shell.execute_reply.started":"2021-11-21T23:19:32.256624Z","shell.execute_reply":"2021-11-21T23:19:32.273732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-21T23:19:32.276612Z","iopub.execute_input":"2021-11-21T23:19:32.276902Z","iopub.status.idle":"2021-11-21T23:19:32.296145Z","shell.execute_reply.started":"2021-11-21T23:19:32.276874Z","shell.execute_reply":"2021-11-21T23:19:32.295444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\nfrom sklearn.tree import DecisionTreeRegressor\n\n\n    ","metadata":{"execution":{"iopub.status.busy":"2021-11-21T23:19:32.297339Z","iopub.execute_input":"2021-11-21T23:19:32.297785Z","iopub.status.idle":"2021-11-21T23:19:32.301248Z","shell.execute_reply.started":"2021-11-21T23:19:32.297754Z","shell.execute_reply":"2021-11-21T23:19:32.300553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_X, val_X, train_y, val_y = train_test_split(X, y,random_state = 0)\n#This gives me a train set and a test set of the data","metadata":{"execution":{"iopub.status.busy":"2021-11-21T23:19:32.302348Z","iopub.execute_input":"2021-11-21T23:19:32.302786Z","iopub.status.idle":"2021-11-21T23:19:32.325284Z","shell.execute_reply.started":"2021-11-21T23:19:32.302758Z","shell.execute_reply":"2021-11-21T23:19:32.323974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n    model.fit(train_X, train_y)\n    preds_val = model.predict(val_X)\n    mae = mean_absolute_error(val_y, preds_val)\n    return(mae)\n#This makes a decision tree using the above chosen categories and returns the mean absolute error","metadata":{"execution":{"iopub.status.busy":"2021-11-21T23:19:32.32664Z","iopub.execute_input":"2021-11-21T23:19:32.326946Z","iopub.status.idle":"2021-11-21T23:19:32.332947Z","shell.execute_reply.started":"2021-11-21T23:19:32.326899Z","shell.execute_reply":"2021-11-21T23:19:32.33191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_mae(2, train_X, val_X, train_y, val_y)\n#This is the MAE for 2 nodes for comparison","metadata":{"execution":{"iopub.status.busy":"2021-11-21T23:19:32.334285Z","iopub.execute_input":"2021-11-21T23:19:32.334693Z","iopub.status.idle":"2021-11-21T23:19:32.407485Z","shell.execute_reply.started":"2021-11-21T23:19:32.334655Z","shell.execute_reply":"2021-11-21T23:19:32.406288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for max_leaf_nodes in [5, 50, 100, 500, 1000, 5000]:\n    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %f\" %(max_leaf_nodes, my_mae))\n#seemingly 500 nodes is the best","metadata":{"execution":{"iopub.status.busy":"2021-11-21T23:19:32.40894Z","iopub.execute_input":"2021-11-21T23:19:32.409268Z","iopub.status.idle":"2021-11-21T23:19:33.6931Z","shell.execute_reply.started":"2021-11-21T23:19:32.409237Z","shell.execute_reply":"2021-11-21T23:19:33.691818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\n\nforest_model = RandomForestRegressor(random_state=1)\nforest_model.fit(train_X, train_y)\nstruct_preds = forest_model.predict(val_X)\nprint(mean_absolute_error(val_y, struct_preds))\n#This runs a random forest model and returns the MAE for that model, which is even better than the 500 nodes. ","metadata":{"execution":{"iopub.status.busy":"2021-11-21T23:19:33.694459Z","iopub.execute_input":"2021-11-21T23:19:33.694744Z","iopub.status.idle":"2021-11-21T23:20:02.114343Z","shell.execute_reply.started":"2021-11-21T23:19:33.694717Z","shell.execute_reply":"2021-11-21T23:20:02.113286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import eli5\nfrom eli5.sklearn import PermutationImportance\n\nperm = PermutationImportance(forest_model, random_state=1).fit(val_X, val_y)\neli5.show_weights(perm, feature_names = val_X.columns.tolist())\n#This checks permutation importance; clearly the bottom three don't matter much. I'm not surprised molecular weight (or residue count) affects resolution... what is surprising is that molecular weight is so much more important than residue count or the various densities.","metadata":{"execution":{"iopub.status.busy":"2021-11-21T23:20:02.115889Z","iopub.execute_input":"2021-11-21T23:20:02.116501Z","iopub.status.idle":"2021-11-21T23:20:25.134308Z","shell.execute_reply.started":"2021-11-21T23:20:02.116455Z","shell.execute_reply":"2021-11-21T23:20:25.133309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import preprocessing\nfrom sklearn import utils\nimport graphviz\nlab_enc = preprocessing.LabelEncoder()\n\nencoded = lab_enc.fit_transform(val_y)\ntree_model = DecisionTreeClassifier(random_state=0, max_depth=5, min_samples_split=5).fit(val_X, encoded)\ntree_graph = tree.export_graphviz(tree_model, out_file=None, feature_names=prediction_features)\ngraphviz.Source(tree_graph)","metadata":{"execution":{"iopub.status.busy":"2021-11-21T23:41:34.054686Z","iopub.execute_input":"2021-11-21T23:41:34.055043Z","iopub.status.idle":"2021-11-21T23:41:34.859077Z","shell.execute_reply.started":"2021-11-21T23:41:34.055012Z","shell.execute_reply":"2021-11-21T23:41:34.858159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from matplotlib import pyplot as plt\n#from pdpbox import pdp, get_dataset, info_plots\n\n## Create the data that we will plot\n#pdp_structuremolecularweight = pdp.pdp_isolate(model=tree_model, dataset=val_X, model_features=prediction_features, feature='structureMolecularWeight')\n\n## plot it\n#pdp.pdp_plot(pdp_structuremolecularweight, 'structureMolecularWeight')\n#plt.show()\n#DOESN'T WORK BECAUSE THE PLOT IS TOO LARGE AND I DON'T KNOW HOW TO FIX THAT","metadata":{"execution":{"iopub.status.busy":"2021-11-21T23:53:06.834753Z","iopub.execute_input":"2021-11-21T23:53:06.835116Z","iopub.status.idle":"2021-11-21T23:53:43.500222Z","shell.execute_reply.started":"2021-11-21T23:53:06.835086Z","shell.execute_reply":"2021-11-21T23:53:43.499009Z"},"trusted":true},"execution_count":null,"outputs":[]}]}